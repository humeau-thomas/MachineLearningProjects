{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x=tf.Variable(3,name='x')\n",
    "y=tf.Variable(4, name='y')\n",
    "f=x*x*y+y+2\n",
    "init=tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result=sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result=f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression on California housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.74651413e+01]\n",
      " [  4.35734153e-01]\n",
      " [  9.33829229e-03]\n",
      " [ -1.06622010e-01]\n",
      " [  6.44106984e-01]\n",
      " [ -4.25131839e-06]\n",
      " [ -3.77322501e-03]\n",
      " [ -4.26648885e-01]\n",
      " [ -4.40514028e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing=fetch_california_housing()\n",
    "m,n=housing.data.shape\n",
    "\n",
    "housing_data_plus_bias=np.c_[np.ones((m,1)), housing.data]\n",
    "\n",
    "X=tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y=tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name='y')\n",
    "XT=tf.transpose(X)\n",
    "\n",
    "theta=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value=theta.eval()\n",
    "\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to scale the data first for better convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data=scaler.fit_transform(housing.data)\n",
    "\n",
    "scaled_housing_data_plus_bias=np.c_[np.ones((m,1)), scaled_housing_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 MSE= 4.85334\n",
      "loop 100 MSE= 0.747335\n",
      "loop 200 MSE= 0.668665\n",
      "loop 300 MSE= 0.639556\n",
      "loop 400 MSE= 0.617165\n",
      "loop 500 MSE= 0.599403\n",
      "loop 600 MSE= 0.585237\n",
      "loop 700 MSE= 0.573893\n",
      "loop 800 MSE= 0.564771\n",
      "loop 900 MSE= 0.557409\n",
      "[[ 2.06855249]\n",
      " [ 0.97460502]\n",
      " [ 0.16666   ]\n",
      " [-0.50069165]\n",
      " [ 0.48311004]\n",
      " [ 0.01104329]\n",
      " [-0.04647031]\n",
      " [-0.4144997 ]\n",
      " [-0.40015447]]\n"
     ]
    }
   ],
   "source": [
    "nloops=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32, name='X')\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32, name='y')\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.,1.), name='theta')\n",
    "y_pred=tf.matmul(X,theta, name='prediction')\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error, name='mse'))\n",
    "\n",
    "gradients=2/m*tf.matmul(tf.transpose(X),error)\n",
    "\n",
    "training_op=tf.assign(theta,theta-learning_rate*gradients)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for loop in range(nloops):\n",
    "        if loop%100==0:\n",
    "            print('loop', loop, 'MSE=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta=theta.eval()\n",
    "    \n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using autodiff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 MSE= 10.9403\n",
      "loop 100 MSE= 0.73624\n",
      "loop 200 MSE= 0.533643\n",
      "loop 300 MSE= 0.526731\n",
      "loop 400 MSE= 0.525957\n",
      "loop 500 MSE= 0.525583\n",
      "loop 600 MSE= 0.52531\n",
      "loop 700 MSE= 0.525099\n",
      "loop 800 MSE= 0.524938\n",
      "loop 900 MSE= 0.524811\n",
      "[[ 2.06855226]\n",
      " [ 0.84255821]\n",
      " [ 0.12524015]\n",
      " [-0.28237295]\n",
      " [ 0.31628352]\n",
      " [-0.00231135]\n",
      " [-0.04015082]\n",
      " [-0.84042633]\n",
      " [-0.81221974]]\n"
     ]
    }
   ],
   "source": [
    "nloops=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32, name='X')\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32, name='y')\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.,1.), name='theta')\n",
    "y_pred=tf.matmul(X,theta, name='prediction')\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error, name='mse'))\n",
    "\n",
    "#difference is here\n",
    "gradients=tf.gradients(mse,[theta])[0]\n",
    "\n",
    "training_op=tf.assign(theta,theta-learning_rate*gradients)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for loop in range(nloops):\n",
    "        if loop%100==0:\n",
    "            print('loop', loop, 'MSE=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta=theta.eval()\n",
    "    \n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 MSE= 3.26923\n",
      "loop 500 MSE= 0.561195\n",
      "loop 1000 MSE= 0.537394\n",
      "loop 1500 MSE= 0.529233\n",
      "loop 2000 MSE= 0.526227\n",
      "loop 2500 MSE= 0.525074\n",
      "loop 3000 MSE= 0.524621\n",
      "loop 3500 MSE= 0.524441\n",
      "loop 4000 MSE= 0.524369\n",
      "loop 4500 MSE= 0.52434\n",
      "[[ 2.06855249]\n",
      " [ 0.83274233]\n",
      " [ 0.11935294]\n",
      " [-0.27139792]\n",
      " [ 0.31053811]\n",
      " [-0.0043248 ]\n",
      " [-0.03944373]\n",
      " [-0.8925699 ]\n",
      " [-0.86358738]]\n"
     ]
    }
   ],
   "source": [
    "nloops=5000\n",
    "learning_rate=0.01\n",
    "\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32, name='X')\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32, name='y')\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.,1.), name='theta')\n",
    "y_pred=tf.matmul(X,theta, name='prediction')\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error, name='mse'))\n",
    "\n",
    "#use an optimizer\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for loop in range(nloops):\n",
    "        if loop%500==0:\n",
    "            print('loop', loop, 'MSE=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta=theta.eval()\n",
    "    \n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mini-batch Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "A=tf.placeholder(tf.float32, shape=(None,3))\n",
    "B=A+5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1=B.eval(feed_dict={A: [[1,2,3]]})\n",
    "    B_val_2=B.eval(feed_dict={A: [[4,5,6], [7,8,9]]})\n",
    "\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 MSE= 0.399021\n",
      "loop 10 MSE= 0.124524\n",
      "loop 20 MSE= 0.124451\n",
      "loop 30 MSE= 0.124403\n",
      "loop 40 MSE= 0.124391\n",
      "loop 50 MSE= 0.124389\n",
      "loop 60 MSE= 0.124388\n",
      "loop 70 MSE= 0.124388\n",
      "loop 80 MSE= 0.124388\n",
      "loop 90 MSE= 0.124388\n",
      "[[ 2.00290895]\n",
      " [ 0.78347152]\n",
      " [ 0.13612019]\n",
      " [-0.23013733]\n",
      " [ 0.27156752]\n",
      " [-0.00706378]\n",
      " [-0.01321162]\n",
      " [-0.86900991]\n",
      " [-0.89599925]]\n"
     ]
    }
   ],
   "source": [
    "nloops=100\n",
    "learning_rate=0.01\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(np.c_[housing.target, scaled_housing_data], columns=['y']+housing.feature_names)\n",
    "df['Bias']=np.ones((m,1))\n",
    "\n",
    "cols=list(df.columns.values)\n",
    "cols_temp=cols[1:len(cols)-1]\n",
    "\n",
    "cols[1]='Bias'\n",
    "cols[2:]=cols_temp\n",
    "\n",
    "df=df[cols]\n",
    "\n",
    "\n",
    "df.to_csv('data.csv',)\n",
    "\n",
    "batch_size=100\n",
    "n_batches=int(np.ceil(m/batch_size))\n",
    "\n",
    "\n",
    "X=tf.placeholder(tf.float32, shape=(None, n+1), name='X')\n",
    "y=tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.,1.), name='theta')\n",
    "y_pred=tf.matmul(X,theta, name='prediction')\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error, name='mse'))\n",
    "\n",
    "#use an optimizer\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for loop in range(nloops):\n",
    "        for batch_index in range(n_batches):\n",
    "            data_batch=df.iloc[batch_index*batch_size: min((batch_index+1)*batch_size, m)]\n",
    "            y_batch=np.asarray(data_batch.y).reshape((-1,1))\n",
    "            X_batch=np.asarray(data_batch[data_batch.columns[1:]])\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if loop%10==0:\n",
    "            print('loop', loop, 'MSE=', mse.eval(feed_dict={X: X_batch, y: y_batch }))\n",
    "    \n",
    "    best_theta=theta.eval()\n",
    "    \n",
    "    print(best_theta)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y',\n",
       " 'Bias',\n",
       " 'MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population',\n",
       "       'AveOccup', 'Latitude', 'Longitude', 'Bias'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
